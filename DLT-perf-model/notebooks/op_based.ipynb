{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn\n",
    "import torch.optim\n",
    "from torch.utils.data import DataLoader\n",
    "from abc import abstractmethod\n",
    "from collections import defaultdict\n",
    "from functools import lru_cache\n",
    "from itertools import count\n",
    "from typing import List, Dict\n",
    "from typing import Tuple, Any\n",
    "from sklearn import ensemble\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from torch.nn import MSELoss, ReLU, L1Loss\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from base_module import MModule\n",
    "from data import MDataset, Graph, load_graphs\n",
    "from importlib import reload\n",
    "from config import Config\n",
    "import config\n",
    "from data import MDataset, Graph, load_graphs, save_dataset_pkl, load_dataset_pkl, save_scalers_pkl, load_scalers_pkl\n",
    "import data\n",
    "from base_module import MModule, nested_detach\n",
    "import base_module\n",
    "from executor import single_train_loop, grid_search_loop\n",
    "import executor\n",
    "from objects import ModelType\n",
    "import objects\n",
    "from metric import MetricUtil\n",
    "import metric\n",
    "from logger import init_logging\n",
    "import logger\n",
    "reload(config)\n",
    "reload(data)\n",
    "reload(base_module)\n",
    "reload(executor)\n",
    "reload(objects)\n",
    "reload(metric)\n",
    "reload(logger)\n",
    "init_logging()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_environment_str = \"P4_CPUALL\"\n",
    "normalizer_cls = StandardScaler  # MinMaxScaler\n",
    "dummy = False\n",
    "op_feature_scaler, y_scaler = None, None\n",
    "eval_graphs = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_configs = {\n",
    "    ModelType.MLP.name: Config.from_dict({\n",
    "        \"model\": \"MLP\",\n",
    "        \"all_seed\": 42,\n",
    "        \"dataset_environment_str\": dataset_environment_str,\n",
    "        \"dataset_normalization\": \"Standard\",\n",
    "        \"dataset_params\": {\n",
    "            \"duration_summed\": False,\n",
    "        },\n",
    "        \"dataset_dummy\": False,\n",
    "        \"batch_size\": 32,\n",
    "        \"eval_steps\": 10000,\n",
    "        \"learning_rate\": 1e-4,\n",
    "        \"epochs\": 10,\n",
    "        \"optimizer\": \"Adam\",\n",
    "        \"meta_configs\": {\n",
    "            \"learning_rate\": 0.005,\n",
    "            \"meta_learning_rate\": 0.001,\n",
    "            \"meta_train_steps\": 1000,\n",
    "            \"meta_task_per_step\": 8,\n",
    "            \"meta_fast_adaption_step\": 5,\n",
    "            \"meta_dataset_train_environment_strs\": [dataset_environment_str],\n",
    "            \"meta_dataset_eval_environment_strs\": [dataset_environment_str],\n",
    "        },\n",
    "    }),\n",
    "    ModelType.PerfNet.name: Config.from_dict({\n",
    "        \"model\": \"PerfNet\",\n",
    "        \"dataset_environment_str\": dataset_environment_str,\n",
    "        \"dataset_normalization\": \"Standard\",\n",
    "        \"all_seed\": 42,\n",
    "        \"dataset_params\": {\n",
    "            \"duration_summed\": False,\n",
    "        },\n",
    "        \"dataset_dummy\": True,\n",
    "        \"batch_size\": 32,\n",
    "        \"eval_steps\": 10000,\n",
    "        \"learning_rate\": 1e-4,\n",
    "        \"epochs\": 10,\n",
    "        \"optimizer\": \"Adam\",\n",
    "        \"meta_configs\": {\n",
    "            \"learning_rate\": 0.005,\n",
    "            \"meta_learning_rate\": 0.001,\n",
    "            \"meta_train_steps\": 1000,\n",
    "            \"meta_task_per_step\": 8,\n",
    "            \"meta_fast_adaption_step\": 5,\n",
    "            \"meta_dataset_train_environment_strs\": [dataset_environment_str],\n",
    "            \"meta_dataset_eval_environment_strs\": [dataset_environment_str],\n",
    "        },\n",
    "    })\n",
    "}\n",
    "\n",
    "model_type = ModelType.MLP\n",
    "conf = train_configs[model_type.name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def init_dataset(graphs: List[Graph]) -> MDataset:\n",
    "    op_X, op_Y = list(), list()\n",
    "    data_idx_to_graph = dict()\n",
    "    counter = iter(count())\n",
    "    op_feature_len = 0\n",
    "\n",
    "    def node_features(g: Graph) -> Tuple[\n",
    "            List[Dict], List[Dict]]:\n",
    "        X, Y = list(), list()\n",
    "        for i, node in enumerate(g.nodes):\n",
    "            x_op_feature = node.op.to_feature_array(\"complex\")\n",
    "            x = {\n",
    "                \"x_op_feature\": x_op_feature\n",
    "            }\n",
    "            # node_durations = (node.duration,node.gap)\n",
    "            node_durations = (node.duration+node.gap,)\n",
    "            x[\"x_id\"] = i\n",
    "            x[\"x_graph_id\"] = g.ID\n",
    "            y = {\"y_node_durations\": node_durations,\n",
    "                 \"y_id\": i, \"y_graph_id\": g.ID}\n",
    "            X.append(x)\n",
    "            Y.append(y)\n",
    "        return X, Y\n",
    "\n",
    "    for graph in graphs:\n",
    "        X, Y = node_features(graph)\n",
    "        for x in X:\n",
    "            # if len(x['x_op_feature'])!=37:\n",
    "            #     print(x['x_graph_id'], len(x['x_op_feature']))\n",
    "            op_feature_len = max(op_feature_len, len(x[\"x_op_feature\"]))\n",
    "        op_X.extend(X)\n",
    "        op_Y.extend(Y)\n",
    "        for i in range(len(X)):\n",
    "            data_idx_to_graph[next(counter)] = graph\n",
    "    for x in op_X:\n",
    "        v = x[\"x_op_feature\"]\n",
    "        x[\"x_op_feature\"] = np.pad(v, (0, op_feature_len - v.size))\n",
    "\n",
    "    dataset = MDataset(op_X, op_Y)\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_scalers(ds):\n",
    "    scaler_cls = normalizer_cls\n",
    "    op_feature_array = list()\n",
    "    y_array = list()\n",
    "\n",
    "    for data in ds:\n",
    "        feature, label = data\n",
    "        op_feature_array.append(feature[\"x_op_feature\"])\n",
    "        y_array.append(label[\"y_node_durations\"])\n",
    "\n",
    "    op_feature_array = np.array(op_feature_array)\n",
    "    y_array = np.array(y_array)\n",
    "\n",
    "    op_feature_scaler = scaler_cls()\n",
    "    op_feature_scaler.fit(op_feature_array)\n",
    "\n",
    "    y_scaler = scaler_cls()\n",
    "    y_scaler.fit(y_array)\n",
    "    return op_feature_scaler, y_scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def preprocess_dataset(ds: MDataset) -> MDataset:\n",
    "    op_feature_array = list()\n",
    "    y_array = list()\n",
    "\n",
    "    for data in ds:\n",
    "        feature, label = data\n",
    "        op_feature_array.append(feature[\"x_op_feature\"])\n",
    "        y_array.append(label[\"y_node_durations\"])\n",
    "\n",
    "    op_feature_array = np.array(op_feature_array, dtype=np.float32)\n",
    "    y_array = np.array(y_array, dtype=np.float32)\n",
    "\n",
    "    op_feature_array = op_feature_scaler.transform(op_feature_array)\n",
    "    y_array = y_scaler.transform(y_array)\n",
    "\n",
    "    processed_features = list()\n",
    "    processed_labels = list()\n",
    "    for i, data in enumerate(ds):\n",
    "        feature, label = data\n",
    "        processed_features.append({\n",
    "            \"x_id\": feature[\"x_id\"],\n",
    "            \"x_graph_id\": feature[\"x_graph_id\"],\n",
    "            # 运行时再传到cuda那边\n",
    "            # \"x_op_feature\": torch.Tensor(op_feature_array[i]).to(device=self.conf.device)\n",
    "            \"x_op_feature\": torch.Tensor(op_feature_array[i])\n",
    "        })\n",
    "        processed_labels.append({\n",
    "            \"y_id\": label[\"y_id\"],\n",
    "            \"y_graph_id\": label[\"y_graph_id\"],\n",
    "            # \"y_node_durations\": torch.Tensor(y_array[i]).to(device=self.conf.device)\n",
    "            \"y_node_durations\": torch.Tensor(y_array[i])\n",
    "        })\n",
    "\n",
    "    ds = MDataset(processed_features, processed_labels)\n",
    "    return ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save_dataset_pkl(preprocessed_train_ds, conf.dataset_environment, \"OpBased\", 'train',\n",
    "#                          conf.dataset_normalization)\n",
    "# save_dataset_pkl(preprocessed_eval_ds, conf.dataset_environment, \"OpBased\", 'eval',\n",
    "#                          conf.dataset_normalization)\n",
    "# save_scalers_pkl(scalers, conf.dataset_environment, \"OpBased\", 'train',\n",
    "#                          conf.dataset_normalization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocessed_train_ds = load_dataset_pkl(conf.dataset_environment, \"OpBased\", 'train',\n",
    "#                                          conf.dataset_normalization)\n",
    "# preprocessed_eval_ds = load_dataset_pkl(conf.dataset_environment, \"OpBased\", 'eval',\n",
    "#                                         conf.dataset_normalization)\n",
    "# scalers = load_scalers_pkl(conf.dataset_environment, \"OpBased\", 'train',\n",
    "#                            conf.dataset_normalization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_evaluate_metrics(input_batches, output_batches, eval_loss) -> Dict[str, float]:\n",
    "    batches_len = len(input_batches)\n",
    "\n",
    "    def compute_op_durations(_logits):\n",
    "        transformed: np.ndarray = y_scaler.inverse_transform(_logits)\n",
    "        durations = transformed.sum(axis=1)\n",
    "        return durations\n",
    "\n",
    "    graph_id_to_duration_pred = defaultdict(int)\n",
    "    for idx in range(batches_len):\n",
    "        inputs = input_batches[idx]\n",
    "        logits = output_batches[idx]\n",
    "        logits = nested_detach(logits)\n",
    "        logits = logits.cpu().numpy()\n",
    "        graph_ids = inputs[\"x_graph_id\"]\n",
    "        op_durations = compute_op_durations(logits)\n",
    "        for i, graph_id in enumerate(graph_ids):\n",
    "            op_duration = op_durations[i].item()\n",
    "            graph_id_to_duration_pred[graph_id] += op_duration\n",
    "    duration_metrics = MetricUtil.compute_duration_metrics(\n",
    "        eval_graphs, graph_id_to_duration_pred)\n",
    "    return {\"eval_loss\": eval_loss, **duration_metrics}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_durations(input_batches, output_batches, scalers, eval_graphs) -> Dict[str, float]:\n",
    "\n",
    "    batches_len = len(input_batches)\n",
    "\n",
    "    def compute_op_durations(_logits):\n",
    "        transformed: np.ndarray = y_scaler.inverse_transform(_logits)\n",
    "        durations = transformed.sum(axis=1)\n",
    "        return durations\n",
    "\n",
    "    graph_id_to_duration_pred = defaultdict(int)\n",
    "    for idx in range(batches_len):\n",
    "        inputs = input_batches[idx]\n",
    "        logits = output_batches[idx]\n",
    "        logits = nested_detach(logits)\n",
    "        logits = logits.cpu().numpy()\n",
    "        graph_ids = inputs[\"x_graph_id\"]\n",
    "        op_durations = compute_op_durations(logits)\n",
    "        for i, graph_id in enumerate(graph_ids):\n",
    "            op_duration = op_durations[i].item()\n",
    "            graph_id_to_duration_pred[graph_id] += op_duration\n",
    "\n",
    "    y_hat, y = list(), list()\n",
    "    for graph in eval_graphs:\n",
    "        y_hat.append(graph_id_to_duration_pred[graph.ID])\n",
    "        y.append(graph.graph_duration)\n",
    "    return np.array(y_hat), np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def to_device(conf, features, labels):\n",
    "    features['x_op_feature'] = features[\"x_op_feature\"].to(device='cuda')\n",
    "    labels['y_node_durations'] = labels['y_node_durations'].to(\n",
    "        device='cuda')\n",
    "    return features, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLPModel(MModule):\n",
    "\n",
    "    @staticmethod\n",
    "    def dimension_len(t):\n",
    "        return t[-1] - t[0]\n",
    "\n",
    "    @staticmethod\n",
    "    def grid_search_model_params() -> Dict[str, List[Any]]:\n",
    "        return {\n",
    "            \"learning_rate\": [1e-3, 1e-4, 1e-5],\n",
    "            'batch_size': [16, 32, 64],\n",
    "            'epochs': [5, 10, 20, 30],\n",
    "            'optimizer': ['Adam', 'SGD'],\n",
    "        }\n",
    "        # return {}\n",
    "\n",
    "    def __init__(self, input_dimension, output_dimension, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.input = torch.nn.Linear(input_dimension, 256)\n",
    "        self.relu1 = ReLU()\n",
    "        self.dense1 = torch.nn.Linear(256, 128)\n",
    "        self.relu2 = ReLU()\n",
    "        self.dense2 = torch.nn.Linear(128, 64)\n",
    "        self.relu3 = ReLU()\n",
    "        self.output = torch.nn.Linear(64, output_dimension)\n",
    "        self.loss_fn = L1Loss()\n",
    "\n",
    "    def forward(self, X):\n",
    "        X = X[\"x_op_feature\"]\n",
    "        X = self.input(X)\n",
    "        X = self.relu1(X)\n",
    "        X = self.dense1(X)\n",
    "        X = self.relu2(X)\n",
    "        X = self.dense2(X)\n",
    "        X = self.relu3(X)\n",
    "        Y = self.output(X)\n",
    "        return Y\n",
    "\n",
    "    def compute_loss(self, outputs, Y):\n",
    "        node_durations = Y[\"y_node_durations\"]\n",
    "        loss = self.loss_fn(outputs, node_durations)\n",
    "        return loss\n",
    "\n",
    "\n",
    "def init_MLP_model() -> MModule | Any:\n",
    "    # sample_preprocessed_ds = preprocessed_train_ds\n",
    "    # sample_x_dict = sample_preprocessed_ds.features[0]\n",
    "    # sample_y_dict = sample_preprocessed_ds.labels[0]\n",
    "    # return MLPModel(input_dimension=len(sample_x_dict[\"x_op_feature\"]),\n",
    "    #                 output_dimension=len(sample_y_dict[\"y_node_durations\"]))\n",
    "    return MLPModel(66, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class PerfNetModel(MModule):\n",
    "    @staticmethod\n",
    "    def dimension_len(t):\n",
    "        return t[-1] - t[0]\n",
    "\n",
    "    @staticmethod\n",
    "    def grid_search_model_params() -> Dict[str, List[Any]]:\n",
    "        return {\n",
    "            \"learning_rate\": [1e-3, 1e-4, 1e-5],\n",
    "            'batch_size': [16, 32, 64],\n",
    "            'epochs': [5, 10, 20, 30],\n",
    "            'optimizer': ['Adam', 'SGD'],\n",
    "        }\n",
    "        # return {}\n",
    "\n",
    "    def __init__(self, output_dimension, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.conv1 = torch.nn.LazyConv1d(\n",
    "            out_channels=32, kernel_size=3, bias=True, padding_mode='zeros')\n",
    "        self.conv2 = torch.nn.LazyConv1d(\n",
    "            out_channels=128, kernel_size=2, bias=True, padding_mode='zeros')\n",
    "        self.flatten = torch.nn.Flatten()\n",
    "        self.dense1 = torch.nn.LazyLinear(32)\n",
    "        self.relu1 = ReLU()\n",
    "        self.dense2 = torch.nn.LazyLinear(64)\n",
    "        self.relu2 = ReLU()\n",
    "        self.dense3 = torch.nn.LazyLinear(128)\n",
    "        self.relu3 = ReLU()\n",
    "        self.dense4 = torch.nn.LazyLinear(256)\n",
    "        self.relu4 = ReLU()\n",
    "        self.dropout = torch.nn.Dropout(p=0.3)\n",
    "        self.output = torch.nn.LazyLinear(output_dimension)\n",
    "        self.loss_fn = L1Loss()\n",
    "\n",
    "    def forward(self, X):\n",
    "        X = X[\"x_op_feature\"]\n",
    "        X = torch.unsqueeze(X, dim=1)\n",
    "        X = self.conv1(X)\n",
    "        X = self.conv2(X)\n",
    "        X = self.flatten(X)\n",
    "        X = self.dense1(X)\n",
    "        X = self.relu1(X)\n",
    "        X = self.dense2(X)\n",
    "        X = self.relu2(X)\n",
    "        X = self.dense3(X)\n",
    "        X = self.relu3(X)\n",
    "        X = self.dense4(X)\n",
    "        X = self.relu4(X)\n",
    "        X = self.dropout(X)\n",
    "        Y = self.output(X)\n",
    "        return Y\n",
    "\n",
    "    def compute_loss(self, outputs, Y):\n",
    "        node_durations = Y[\"y_node_durations\"]\n",
    "        loss = self.loss_fn(outputs, node_durations)\n",
    "        return loss\n",
    "\n",
    "\n",
    "def init_PerfNet_model() -> MModule | Any:\n",
    "    # sample_y_dict = preprocessed_train_ds.labels[0]\n",
    "    # print(len(sample_y_dict[\"y_node_durations\"]))\n",
    "    # return PerfNetModel(output_dimension=len(sample_y_dict[\"y_node_durations\"]))\n",
    "    return PerfNetModel(output_dimension=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# eval_process\n",
    "eval_size = 200_000\n",
    "batch_size = 32\n",
    "method_prefix = 'OpBased'\n",
    "models = {\n",
    "    'T4_CPUALL': '/root/guohao/DLT-perf-model/notebooks/ckpts/op_based/T4_CPUALL/PerfNet/single_train2024-01-09_12-45-50/ckpt_835000.pth',\n",
    "    'P4_CPUALL': '/root/guohao/DLT-perf-model/notebooks/ckpts/op_based/P4_CPUALL/PerfNet/single_train2024-01-09_14-06-21/ckpt_305000.pth',\n",
    "    'RTX2080Ti_CPUALL': '/root/guohao/DLT-perf-model/notebooks/ckpts/op_based/RTX2080Ti_CPUALL/PerfNet/single_train2024-01-09_15-00-18/ckpt_930000.pth',\n",
    "    'RTX3080Ti_CPUALL': '/root/guohao/DLT-perf-model/notebooks/ckpts/op_based/RTX3080Ti_CPUALL/PerfNet/single_train2024-01-09_16-24-24/ckpt_815000.pth',\n",
    "}\n",
    "res = []\n",
    "for dataset_environment_str, model_ckpt in models.items():\n",
    "    eval_graphs = load_graphs(dataset_environment_str,\n",
    "                              train_or_eval=\"eval\",\n",
    "                              use_dummy=False,\n",
    "                              max_row=eval_size)\n",
    "\n",
    "    eval_ds = init_dataset(eval_graphs)\n",
    "    scalers = load_scalers_pkl(dataset_environment_str, method_prefix, 'train',\n",
    "                               'Standard')\n",
    "    op_feature_scaler, y_scaler = scalers\n",
    "    preprocessed_eval_ds = preprocess_dataset(eval_ds)\n",
    "    model = torch.load(model_ckpt)\n",
    "    model.eval()\n",
    "    ds = preprocessed_eval_ds\n",
    "    dl = DataLoader(ds, batch_size=batch_size, shuffle=False)\n",
    "    input_batchs, output_batchs = list(), list()\n",
    "    for data in dl:\n",
    "\n",
    "        features, labels = data\n",
    "        features, labels = to_device(\"cuda\", features, labels)\n",
    "        with torch.no_grad():\n",
    "            outputs = model(features)\n",
    "        input_batchs.append(features)\n",
    "        output_batchs.append(outputs)\n",
    "    y_hat, y = compute_durations(\n",
    "        input_batchs, output_batchs, scalers, eval_graphs)\n",
    "    rand_y, rand_y_hat = [], []\n",
    "    models_y, models_y_hat = [], []\n",
    "    for i in range(len(eval_graphs)):\n",
    "        graph = eval_graphs[i]\n",
    "        if 'rand' in graph.ID:\n",
    "            rand_y.append(y[i])\n",
    "            rand_y_hat.append(y_hat[i])\n",
    "        else:\n",
    "            models_y.append(y[i])\n",
    "            models_y_hat.append(y_hat[i])\n",
    "    res.append(\n",
    "        {\n",
    "            'dataset': dataset_environment_str,\n",
    "            'mre': MetricUtil.mre(y, y_hat),\n",
    "            'rmse': MetricUtil.rmse(y, y_hat),\n",
    "            'rand_mre': MetricUtil.mre(rand_y, rand_y_hat),\n",
    "            'rand_rmse': MetricUtil.rmse(rand_y, rand_y_hat),\n",
    "            'models_mre': MetricUtil.mre(models_y, models_y_hat),\n",
    "            'models_rmse': MetricUtil.rmse(models_y, models_y_hat),\n",
    "        }\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "df = pd.DataFrame(res)\n",
    "df.to_csv(os.path.join('/root/guohao/DLT-perf-model/notebooks/exp/total_compare',\n",
    "          f'OpBased.result.csv'), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# envs = ['T4_CPUALL', 'P4_CPUALL', 'RTX2080Ti_CPUALL', 'RTX3080Ti_CPUALL',\n",
    "#         'T4_CPU100', 'P4_CPU100', 'RTX2080Ti_CPU100', 'T4_CPU80', 'P4_CPU80']\n",
    "envs = ['T4_CPUALL', 'P4_CPUALL', 'RTX2080Ti_CPUALL', 'RTX3080Ti_CPUALL']\n",
    "for env in envs:\n",
    "    train_configs = {\n",
    "        ModelType.MLP.name: Config.from_dict({\n",
    "            \"model\": \"MLP\",\n",
    "            \"all_seed\": 42,\n",
    "            \"dataset_environment_str\": env,\n",
    "            \"dataset_normalization\": \"Standard\",\n",
    "            \"dataset_params\": {\n",
    "                \"duration_summed\": False,\n",
    "            },\n",
    "            \"dataset_dummy\": False,\n",
    "            \"batch_size\": 32,\n",
    "            \"eval_steps\": 10000,\n",
    "            \"learning_rate\": 1e-4,\n",
    "            \"epochs\": 10,\n",
    "            \"optimizer\": \"Adam\",\n",
    "            \"meta_configs\": {\n",
    "                \"learning_rate\": 0.005,\n",
    "                \"meta_learning_rate\": 0.001,\n",
    "                \"meta_train_steps\": 1000,\n",
    "                \"meta_task_per_step\": 8,\n",
    "                \"meta_fast_adaption_step\": 5,\n",
    "                \"meta_dataset_train_environment_strs\": [dataset_environment_str],\n",
    "                \"meta_dataset_eval_environment_strs\": [dataset_environment_str],\n",
    "            },\n",
    "        }),\n",
    "        ModelType.PerfNet.name: Config.from_dict({\n",
    "            \"model\": \"PerfNet\",\n",
    "            \"dataset_environment_str\": env,\n",
    "            \"dataset_normalization\": \"Standard\",\n",
    "            \"all_seed\": 42,\n",
    "            \"dataset_params\": {\n",
    "                \"duration_summed\": False,\n",
    "            },\n",
    "            \"dataset_dummy\": True,\n",
    "            \"batch_size\": 32,\n",
    "            \"eval_steps\": 5000,\n",
    "            \"learning_rate\": 1e-4,\n",
    "            \"epochs\": 30,\n",
    "            \"optimizer\": \"Adam\",\n",
    "            \"meta_configs\": {\n",
    "                \"learning_rate\": 0.005,\n",
    "                \"meta_learning_rate\": 0.001,\n",
    "                \"meta_train_steps\": 1000,\n",
    "                \"meta_task_per_step\": 8,\n",
    "                \"meta_fast_adaption_step\": 5,\n",
    "                \"meta_dataset_train_environment_strs\": [dataset_environment_str],\n",
    "                \"meta_dataset_eval_environment_strs\": [dataset_environment_str],\n",
    "            },\n",
    "        })\n",
    "    }\n",
    "    # eval_graphs = load_graphs(env,\n",
    "    #                           train_or_eval=\"eval\",\n",
    "    #                           use_dummy=dummy,\n",
    "    #                           max_row=200_000)\n",
    "    train_graphs = load_graphs(env,\n",
    "                               train_or_eval=\"train\",\n",
    "                               use_dummy=dummy,\n",
    "                               max_row=1000_000)\n",
    "    train_ds = init_dataset(train_graphs)\n",
    "    eval_ds = init_dataset(eval_graphs)\n",
    "    scalers = get_scalers(train_ds)\n",
    "    save_scalers_pkl(scalers, env, \"OpBased\", 'train',\n",
    "                     conf.dataset_normalization)\n",
    "    op_feature_scaler, y_scaler = scalers\n",
    "\n",
    "    preprocessed_train_ds = preprocess_dataset(train_ds)\n",
    "    preprocessed_eval_ds = preprocess_dataset(eval_ds)\n",
    "\n",
    "    model_type = ModelType.PerfNet\n",
    "    conf = train_configs[model_type.name]\n",
    "    init_model_funcs = {\n",
    "        ModelType.MLP.name: init_MLP_model,\n",
    "        ModelType.PerfNet.name: init_PerfNet_model,\n",
    "    }\n",
    "\n",
    "    model_type = ModelType.PerfNet\n",
    "    init_model = init_model_funcs[model_type.name]\n",
    "\n",
    "    model = init_model()\n",
    "    model = model.to(conf.device)\n",
    "    single_train_loop(model_type, conf, preprocessed_train_ds,\n",
    "                      preprocessed_eval_ds, model, compute_evaluate_metrics, to_device, suffix=\"op_based\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DLT-perf-model",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
